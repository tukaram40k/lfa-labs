# Lab 5 Report: Chomsky Normal Form

### Course: Formal Languages & Finite Automata
### Author: Ivan Rudenco

----

## Theory:
Context-Free Grammars (CFGs) are formal grammars used to generate context-free languages. They consist of variables (non-terminal symbols), terminals (symbols that appear in the language), productions (rules for replacing variables), and a start symbol. The Chomsky Normal Form (CNF) is a simplified form of context-free grammars where all production rules have either the form A → BC (where B and C are non-terminals) or A → a (where a is a terminal). Converting a CFG to CNF is essential for various parsing algorithms, such as the CYK algorithm, which efficiently determines whether a string can be generated by a given grammar. This transformation preserves the language generated by the original grammar while standardizing its structure for easier processing.

## Objectives:
1. Learn about Chomsky Normal Form (CNF).

2. Get familiar with the approaches of normalizing a grammar.
3. Implement a method for normalizing an input grammar by the rules of CNF.
    1. The implementation needs to be encapsulated in a method with an appropriate signature (also ideally in an appropriate class/type).
    2. The implemented functionality needs executed and tested.
    3. Also, another **BONUS point** would be given if the student will make the aforementioned function to accept any grammar, not only the one from the student's variant.


## Implementation description

The implementation consists of a ToCNF class that performs the conversion of a context-free grammar to Chomsky Normal Form through a series of systematic transformations. The class is initialized with the non-terminal symbols (`vn`), terminal symbols (`vt`), production rules (`p`), and start symbol (`s`).

In order to have multiple options for new `vn`s, I anned a long list of free characters to serve as potential variables.

```py
en_ch = [chr(i) for i in range(ord('A'), ord('Z') + 1)]
ru_ch = [chr(i) for i in range(ord('А'), ord('Я') + 1)]
for ch in ['А', 'В', 'С', 'Е', 'К', 'Н', 'Р', 'О', 'Т', 'М', 'У', 'Х']:
    if ch in ru_ch:
        ru_ch.remove(ch)
cn_ch = [chr(i) for i in range(int('0x4E00', 16) + 500, int('0x9FFF', 16) + 1)]
self.free_chars = en_ch + ru_ch + cn_ch
```

### 1. Removal of start symbol from the right side

The first transformation makes sure that the start symbol doesn't appear on the right side of any production rule:

```py
for vn, rules in self.p.items():
    for rule in rules:
        if self.s in rule:
            new_s = self.next_free_ch()
            self.p[new_s] = [self.s]
            self.s = new_s
            self.vn.append(new_s)
            return
```

### 2. Removal of null productions

Chains of symbols leading to epsilon are removed, and new production rules are added.

```py
while changed:
    changed = False
    for A in self.p:
        if A not in nullable:
            for rule in self.p[A]:
                if rule == 'epsilon' or all(symbol in nullable for symbol in rule):
                    nullable.add(A)
                    changed = True
                    break
```

### 3. Removal of unit productions

Symbols that produce a single non-terminal are replaced by new production rules for other symbols.

```py
unit_pairs = {vn: set() for vn in self.vn}

    for A in self.vn:
        for rule in self.p[A]:
            if len(rule) == 1 and rule in self.vn:
                unit_pairs[A].add(rule)
```

### 4. Removal of extra variables

Production rules with more than two variables on the right side are broken into smaller ones by introducing new variables.

```py
productions = list(self.p.items())
for A, rules in productions:
    new_rules = []
    for rule in rules:
        if len(rule) <= 2:
            new_rules.append(rule)
```

### 5. Removing mixed up Vn and Vt

Production rules with both terminals and non-terminals on the right side are replaced with additional variables.

```py
term_to_var = {}
    for terminal in self.vt:
        if terminal not in term_to_var:
            new_var = self.next_free_ch()
            term_to_var[terminal] = new_var
            self.vn.append(new_var)
            self.p[new_var] = [terminal]
```

Lastly, repetition is handled, and the symbols are repeated 0 or 1 time in case of `?`, 0 or more times in case of `*`, and 1 or more times in case of `+`. To prevent generation of very long strings, the maximum number of repetitions is capped at 5.

```py
elif last == '?':
    if r.randint(0, 1) == 1:
        result.append(r.choice(chars))
elif last == '+':
    ch = r.choice(chars)
    for _ in range(r.randint(1, 5)):
        result.append(ch)
elif last == '*':
    ch = r.choice(chars)
    for _ in range(r.randint(0, 5)):
        result.append(ch)
```

To better show how string generation works, I made a helper method that generates and prints `n` unique strings for each given regular expression.

```py
def generate_str(self, n):
    results = []
    
    while len(results) < n:
        str = self.get_str()
        if str not in results: results.append(str)
```

## Conclusions / Screenshots / Results

The results of generating 5 valid string according to my variant will look like this:

```
['acEEG', 'PSTUVUVUVUVZZZZ', '11124444436']
['acEEEEEG', 'PRTXZZZZZ', '111123333336']
['bdE', 'PSTZZZZ', '1024444436']
['bdEG', 'PSTWZZZZ', '1111123333336']
['bcEEG', 'PRTUVUVUVUVUVZZ', '1111123333336']
```

In conclusion, this lab was a great hands-on experience with regular expressions, showing how they can be used dynamically to generate valid strings. By breaking down each regex pattern into smaller parts and applying the correct operations, the program successfully produced strings that matched the given rules. One of the biggest challenges was correctly handling repetition operators like *, +, and ?, and correctly identifying which group of characters they belong to. Despite some trial and error, the final implementation worked well, generating accurate outputs that. Overall, this lab helped me better undersnand regex in text processing and gave me a deeper understanding of how to find string patterns programmatically.

## References
- [good ol' friend](https://chatgpt.com/)